{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0cfe07b014d4870367da8a0513530648d8087115be69e8698b1821f7bb106330b",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Binäre Klassifikation anhand eines Spam-Filters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Technische Vorbereitung\n",
    "Damit alle notwendigen Funktionen und Befehle zur Verfügung stehen, müssen zunächst einige Module mit ihren jeweiligen Klassen importiert werden. Dazu zählt pandas und scikit-learn. Alle Module werden für spätere Datenanalysemethoden genutzt.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "from pandas import set_option\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "source": [
    "## Analyse des Datensatzes\n",
    "Der Datensatz liegt hierbei in einer \".csv\" - Datei und beinhaltet 5572 Datensätze. Er ist in zwei Spalten untergliedert. Die Spalte Label beinhaltet die Gruppen Spam und Ham die den jeweiligen Datensatz zugeordnet sind. Bei der zweiten Spalte handelt es sich um den EmailText.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Label                                          EmailText\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...\n\n       Label               EmailText\ncount   5572                    5572\nunique     2                    5169\ntop      ham  Sorry, I'll call later\nfreq    4825                      30\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"spam.csv\")\n",
    "print(dataframe.head())\n",
    "print(\"\")\n",
    "print(dataframe.describe())\n"
   ]
  },
  {
   "source": [
    "Sowohl Label als auch der EmailText besitzen den Datentyp object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label        object\nEmailText    object\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.dtypes)\n"
   ]
  },
  {
   "source": [
    "Durch den folgenden Code wurde die Anzahl von Spam- bzw. Ham-Emails in dem Datensatz gezählt. Dabei fällt auf, dass es sehr unausgeglichen ist und es sich bei den meisten Nachrichten um ham-Emails handelt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Anzahl ham  - Emails:  4825\nAnzahl spam - Emails:  747\n"
     ]
    }
   ],
   "source": [
    "hamCount = dataframe.apply(lambda x: True if x[\"Label\"] == \"ham\" else False, axis=1)\n",
    "spamCount = dataframe.apply(lambda x: True if x[\"Label\"] == \"spam\" else False, axis=1)\n",
    "\n",
    "print(\"Anzahl ham  - Emails: \", len(hamCount[hamCount == True].index))\n",
    "print(\"Anzahl spam - Emails: \", len(spamCount[spamCount == True].index))\n"
   ]
  },
  {
   "source": [
    "## Traings- und Testdaten\n",
    "Im nächsten Schritt werden die Daten in den Spalten separiert und danach gruppiert. Die Trainingsdaten werden für das Lernen der Muster und Zusammenhänge in den Daten verwendet. Der Algorithmus nutzt diese Daten um daraus zu lernen. Bei den Testdaten handelt es sich um Daten mit der gleichen Wahrscheinlichkeitsverteilung. Diese Daten werden vom Algorithmus vorher nicht genutzt. Mit ihnen kann nachgeweisen werden mit welcher Qualität der Algorithmus auf neue Daten reagieren wird. Die Verteilung verläuft auf 80% Trainingsdaten und 20% Testdaten."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe[\"EmailText\"]\n",
    "y = dataframe[\"Label\"]\n",
    "\n",
    "x_train,y_train = x[0:4457],y[0:4457]\n",
    "x_test,y_test = x[4457:],y[4457:]"
   ]
  },
  {
   "source": [
    "## Transformieren der Daten\n",
    "Nachdem die Daten gruppiert wurden müssen die Strings in numerische Werte umgewandelt werden, damit der Klassifikator die Daten nutzen kann. Scikit-Learn stellt hierbei einen \"CountVectorizer\" zur Verfügung. Er konvertiert eine Sammlung von Text Dokumenten in eine Matrix mit Token-Zahlen"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()  \n",
    "features = cv.fit_transform(x_train)"
   ]
  },
  {
   "source": [
    "## Klassifikator\n",
    "Für den Spam-Filter wird der Support-Vector-Machine-Klassifikator genutzt. Damit die einzelnen Klassen einen möglichst breiten Abstand ohne Objekte zueinander besitzen. Des Weiteren müssen auch die Testdaten transformiert werden. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Die Genauigkeit des Models entspricht: 0.9856502242152466\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(features,y_train)\n",
    "\n",
    "features_test = cv.transform(x_test)\n",
    "print(\"Die Genauigkeit des Models entspricht:\", model.score(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Die Genauigkeit des Models entspricht: 0.9874439461883409\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'kernel': ['rbf','linear'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}\n",
    "\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters)\n",
    "\n",
    "model.fit(features,y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "features_test = cv.transform(x_test)\n",
    "print(\"Die Genauigkeit des Models entspricht:\", model.score(features_test,y_test))"
   ]
  }
 ]
}