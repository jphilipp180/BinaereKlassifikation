{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0cfe07b014d4870367da8a0513530648d8087115be69e8698b1821f7bb106330b",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Binäre Klassifikation anhand eines Spam-Filters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Thema\n",
    "In dieser Binären Klassifikation handelt es sich um die Vorhersage auf das Eintreffen einer Spam-Email oder einer Ham-Email. Um dies herauszufinden wird ein Datensatz der mehrere Spam-/Ham-Emails mit EmailText enthält verwendet."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Technische Vorbereitung\n",
    "Damit alle notwendigen Funktionen und Befehle zur Verfügung stehen, müssen zunächst einige Module mit ihren jeweiligen Klassen importiert werden. Dazu zählt pandas und scikit-learn. Alle Module werden für spätere Datenanalysemethoden genutzt.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "#from pandas import set_option\n",
    "from matplotlib import pyplot\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [
    "## Analyse des Datensatzes\n",
    "Der Datensatz liegt hierbei in einer \".csv\" - Datei und beinhaltet 5572 Datensätze. Er ist in zwei Spalten untergliedert. Die Spalte Label beinhaltet die Gruppen Spam und Ham die den jeweiligen Datensatz zugeordnet sind. Bei der zweiten Spalte handelt es sich um den EmailText.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Label                                          EmailText\n0   ham  Go until jurong point, crazy.. Available only ...\n1   ham                      Ok lar... Joking wif u oni...\n2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3   ham  U dun say so early hor... U c already then say...\n4   ham  Nah I don't think he goes to usf, he lives aro...\n\n       Label               EmailText\ncount   2000                    2000\nunique     2                    1925\ntop      ham  Sorry, I'll call later\nfreq    1720                      13\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"spam.csv\")\n",
    "print(dataframe.head())\n",
    "print(\"\")\n",
    "print(dataframe.describe())\n"
   ]
  },
  {
   "source": [
    "Sowohl Label als auch der EmailText besitzen den Datentyp object."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Label        object\nEmailText    object\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dataframe.dtypes)\n"
   ]
  },
  {
   "source": [
    "Durch den folgenden Code wurde die Anzahl von Spam- bzw. Ham-Emails in dem Datensatz gezählt. Dabei fällt auf, dass es sehr unausgeglichen ist und es sich bei den meisten Nachrichten um ham-Emails handelt."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Anzahl ham  - Emails:  1720\nAnzahl spam - Emails:  280\n"
     ]
    }
   ],
   "source": [
    "hamCount = dataframe.apply(lambda x: True if x[\"Label\"] == \"ham\" else False, axis=1)\n",
    "spamCount = dataframe.apply(lambda x: True if x[\"Label\"] == \"spam\" else False, axis=1)\n",
    "\n",
    "print(\"Anzahl ham  - Emails: \", len(hamCount[hamCount == True].index))\n",
    "print(\"Anzahl spam - Emails: \", len(spamCount[spamCount == True].index))\n"
   ]
  },
  {
   "source": [
    "## Traings- und Testdaten\n",
    "Im nächsten Schritt werden die Daten in den Spalten separiert und danach gruppiert. Die Trainingsdaten werden für das Lernen der Muster und Zusammenhänge in den Daten verwendet. Der Algorithmus nutzt diese Daten um daraus zu lernen. Bei den Testdaten handelt es sich um Daten mit der gleichen Wahrscheinlichkeitsverteilung. Diese Daten werden vom Algorithmus vorher nicht genutzt. Mit ihnen kann nachgeweisen werden mit welcher Qualität der Algorithmus auf neue Daten reagieren wird. Die Verteilung verläuft auf 80% Trainingsdaten und 20% Testdaten."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataframe[\"EmailText\"]\n",
    "y = dataframe[\"Label\"]\n",
    "\n",
    "x_train,y_train = x[0:4457],y[0:4457]\n",
    "x_test,y_test = x[4457:],y[4457:]"
   ]
  },
  {
   "source": [
    "## Transformieren der Daten\n",
    "Nachdem die Daten gruppiert wurden müssen die Strings in numerische Werte umgewandelt werden, damit der Klassifikator die Daten nutzen kann. Scikit-Learn stellt hierbei einen \"CountVectorizer\" zur Verfügung. Er konvertiert eine Sammlung von Text Dokumenten in eine Matrix mit Token-Zahlen. Die Matrix baut sich aus 4457 Zeilen (EmailTexte) und 7756 Spalten (Anzahl unterschiedlicher Wörter) zusammen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2000, 4973)\n[[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()  \n",
    "featuresX = cv.fit_transform(x_train)\n",
    "\n",
    "print(featuresX.shape)\n",
    "print(featuresX.toarray())\n"
   ]
  },
  {
   "source": [
    "## Evaluierung der Algorithmen\n",
    "Im folgenden Code wird mit Hilfe der Genauigkeit der beste Algorithmus herausgefunden. Die Genauigkeit wird dabei anhand des Mittelwertes und der Standardabweichung gemessen. Es stellt sich heraus, dass die logistische Regression und der Support-Vector-Machine-Klassifikator am besten geeignet sind."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR: 0.971000 (0.015297)\n",
      "NB: 0.913000 (0.023685)\n",
      "SVM: 0.965000 (0.008660)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append((\"LR\", LogisticRegression()))\n",
    "models.append((\"NB\", GaussianNB()))\n",
    "models.append((\"SVM\", SVC()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    cv_results = cross_val_score(model, featuresX.toarray(), y_train, cv=kfold, scoring=\"accuracy\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "source": [
    "## Evaluierung der Algorithmen mit Hilfe der Standardisierung\n",
    "In diesem Code werden alle Merkmale so transformiert, dass sie einen Mittelwert von 0 und eine Standardabweichung von 1 besitzen. Durch die Verwendung von pipelines wird Datenverlust vermieden. Dabei fällt auf das die Genauigkeit bei allen drei Algorithem gesunken ist. Die logistische Regression und der Support-Vektor-Machine-Klassifikator sind trotzdem noch die bessern."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ScaledLR: 0.959000 (0.012207)\n",
      "ScaledNB: 0.900000 (0.016279)\n",
      "ScaledSVM: 0.911000 (0.018682)\n"
     ]
    }
   ],
   "source": [
    "pipelines = []\n",
    "pipelines.append((\"ScaledLR\", Pipeline([(\"Scaler\", StandardScaler()), (\"LR\", LogisticRegression())])))\n",
    "pipelines.append((\"ScaledNB\", Pipeline([(\"Scaler\", StandardScaler()), (\"NB\", GaussianNB())])))\n",
    "pipelines.append((\"ScaledSVM\", Pipeline([(\"Scaler\", StandardScaler()), (\"SVM\", SVC())])))\n",
    "\n",
    "results =[]\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    cv_results = cross_val_score(model, featuresX.toarray(), y_train, cv=kfold, scoring=\"accuracy\")\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "source": [
    "## Verbesserung der Algorithmen\n",
    "Durch das Verändern/Anpassen von Parametern für einen jeweiligen Algroithmus kann seine Genauigkeit erhöht werde.n\n",
    "\n",
    "### Verbesserung des Support-Vector-Machine-Klassifikator\n",
    "Beim SVM lassen sich zwei Parameter anpassen. Zum einen der Kernel und zum anderen der C-Wert. Der Kernel versucht den Trainingsvektor in verschiedene höherdimensionale Räume zu überführen, damit die Vektoren sich leichter trennen lassen. Beim C-Wert wird dem Klassifikator mitgeteilt wie sehr er eine Fehlklassifizierung vermeiden soll. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best: 0.969000 using {'C': 2.0, 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler().fit(featuresX.toarray())\n",
    "rescaledX = scaler.transform(featuresX.toarray())\n",
    "c_values = [0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "kernel_values = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "param_grid = dict(C=c_values, kernel=kernel_values)\n",
    "model = SVC()\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=\"accuracy\", cv=kfold)\n",
    "grid_result = grid.fit(rescaledX, y_train)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "#means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "#stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "#params = grid_result.cv_results_[\"params\"]"
   ]
  },
  {
   "source": [
    "## Klassifikator\n",
    "Für den Spam-Filter wird der Support-Vector-Machine-Klassifikator genutzt. Damit die einzelnen Klassen einen möglichst breiten Abstand ohne Objekte zueinander besitzen. Des Weiteren müssen auch die Testdaten transformiert werden. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Die Genauigkeit des Models entspricht: 0.9856502242152466\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC()\n",
    "model.fit(features,y_train)\n",
    "\n",
    "features_test = cv.transform(x_test)\n",
    "print(\"Die Genauigkeit des Models entspricht:\", model.score(features_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Die Genauigkeit des Models entspricht: 0.9874439461883409\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters = {'kernel': ['rbf','linear'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]}\n",
    "\n",
    "model = GridSearchCV(svm.SVC(), tuned_parameters)\n",
    "\n",
    "model.fit(features,y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "features_test = cv.transform(x_test)\n",
    "print(\"Die Genauigkeit des Models entspricht:\", model.score(features_test,y_test))"
   ]
  }
 ]
}